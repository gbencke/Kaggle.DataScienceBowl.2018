{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple MNist like model for detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using as example:\n",
    "https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import gzip\n",
    "import pickle\n",
    "import gc\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "PATH_TO_INTERMEDIATE = \"../data/intermediate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(\"x_train:\", x_train.shape)\n",
    "print(x_train[:1])\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(y_train[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles = [join(PATH_TO_INTERMEDIATE, x) for x in listdir(PATH_TO_INTERMEDIATE) if isfile(join(PATH_TO_INTERMEDIATE, x)) and x.endswith(\".pickle\")]\n",
    "shuffle(onlyfiles)\n",
    "\n",
    "print(\"Original number of files:\", len(onlyfiles))\n",
    "\n",
    "onlyfiles = onlyfiles[:20]\n",
    "\n",
    "train_files_size = int(len(onlyfiles) * 0.5)\n",
    "train_files = onlyfiles[0:train_files_size]\n",
    "onlyfiles = onlyfiles[train_files_size:]\n",
    "\n",
    "validation_files_size = int(len(onlyfiles) * 0.5)\n",
    "validation_files = onlyfiles[0:validation_files_size]\n",
    "onlyfiles = onlyfiles[validation_files_size:]\n",
    "\n",
    "test_files_size = len(onlyfiles) \n",
    "test_files = onlyfiles[0:test_files_size]\n",
    "onlyfiles = onlyfiles[test_files_size:]\n",
    "\n",
    "print('train_files:', len(train_files))\n",
    "print('validation_files:', len(validation_files))\n",
    "print('test_files:', len(test_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "validation_x = []\n",
    "validation_y = []\n",
    "\n",
    "test_x = []\n",
    "test_y = []\n",
    "for current_file in train_files:\n",
    "    sample = []\n",
    "    with gzip.open(current_file,'r') as f:\n",
    "        sample = pickle.load(f)\n",
    "    for current_sample in sample['slices']:\n",
    "        train_x.append(current_sample['slice'])\n",
    "        train_y.append(current_sample['is_nuclei'])\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train_x:', train_x.shape)\n",
    "print('train_y:', train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample['slices'][0]['slice'].shape)\n",
    "\n",
    "print(sample['slices'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = []\n",
    "\n",
    "total.append(sample['slices'][0]['slice'])\n",
    "total.append(sample['slices'][1]['slice'])\n",
    "\n",
    "total = np.array(total)\n",
    "\n",
    "print(total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
