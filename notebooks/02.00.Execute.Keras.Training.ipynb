{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import h5py\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "from datetime import datetime\n",
    "\n",
    "import logging\n",
    "import gzip\n",
    "import pickle\n",
    "import gc\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_location = \"../logs/\"\n",
    "PATH_TO_INTERMEDIATE = \"../data/intermediate\"\n",
    "PATH_TO_MODELS = \"../data/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logging.basicConfig(format=\"%(asctime)-15s %(message)s\",\n",
    "                    level=logging.DEBUG,\n",
    "                    filename=os.path.join(log_location,'csv.' + datetime.now().strftime(\"%Y%m%d%H%M%S.%f\") + '.log'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IsDevelopmentEnvironment():\n",
    "    return True\n",
    "\n",
    "DevelopmentEnvironment = IsDevelopmentEnvironment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(msg):\n",
    "    logging.debug(msg)\n",
    " \n",
    "def print_log(msg):\n",
    "    log(msg)\n",
    "    print(msg)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches_x = sorted([join(PATH_TO_INTERMEDIATE, x) for x in listdir(PATH_TO_INTERMEDIATE) if isfile(join(PATH_TO_INTERMEDIATE, x)) and x.endswith(\"x.pickle\")  and x.startswith('train')])\n",
    "validation_batches_x = sorted([join(PATH_TO_INTERMEDIATE, x) for x in listdir(PATH_TO_INTERMEDIATE) if isfile(join(PATH_TO_INTERMEDIATE, x)) and x.endswith(\"x.pickle\") and x.startswith('validation')])\n",
    "test_batches_x= sorted([join(PATH_TO_INTERMEDIATE, x) for x in listdir(PATH_TO_INTERMEDIATE) if isfile(join(PATH_TO_INTERMEDIATE, x)) and x.endswith(\"x.pickle\") and x.startswith('test')])\n",
    "\n",
    "print_log(\"Original number of train batches:{}\".format(len(train_batches_x)))\n",
    "print_log(\"Original number of validation batches:{}\".format(len(validation_batches_x)))\n",
    "print_log(\"Original number of test batches:{}\".format(len(test_batches_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = None\n",
    "train_y = None\n",
    "\n",
    "validation_x = None\n",
    "validation_y = None\n",
    "\n",
    "test_x = None\n",
    "test_y = None\n",
    "\n",
    "current_train_batch = 0\n",
    "current_validation_batch = 0\n",
    "current_test_batch = 0\n",
    "\n",
    "print_log(\"Finished Resetting the global arrays...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_train_batch_file_name_x = join(PATH_TO_INTERMEDIATE, \"train.batch.{}.x.pickle\".format(current_train_batch))\n",
    "current_train_batch_file_name_y = join(PATH_TO_INTERMEDIATE, \"train.batch.{}.y.pickle\".format(current_train_batch))\n",
    "with gzip.open(current_train_batch_file_name_x,'rb') as f:\n",
    "    train_x = pickle.load(f)\n",
    "with gzip.open(current_train_batch_file_name_y,'rb') as f:\n",
    "    train_y = pickle.load(f) \n",
    "print_log(\"Finished Reading the sample train batches...\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_test_batch_file_name_x = join(PATH_TO_INTERMEDIATE, \"test.batch.{}.x.pickle\".format(current_test_batch))\n",
    "current_test_batch_file_name_y = join(PATH_TO_INTERMEDIATE, \"test.batch.{}.y.pickle\".format(current_test_batch))\n",
    "with gzip.open(current_test_batch_file_name_x,'rb') as f:\n",
    "    test_x = pickle.load(f)\n",
    "with gzip.open(current_test_batch_file_name_y,'rb') as f:\n",
    "    test_y = pickle.load(f)   \n",
    "print_log(\"Finished Reading the sample test batches...\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 10\n",
    "global_epochs = 100\n",
    "development_machine_samples = 10000\n",
    "img_rows, img_cols = train_x.shape[1], train_x.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = True\n",
    "\n",
    "total_validation_x = None\n",
    "total_validation_y = None\n",
    "\n",
    "validation_x = None\n",
    "validation_y = None\n",
    "\n",
    "for current_validation in validation_batches_x:\n",
    "    print_log(\"Merging Validation Batch:{}\".format(current_validation))\n",
    "    with gzip.open(current_validation,'rb') as f:\n",
    "        validation_x = pickle.load(f)\n",
    "    with gzip.open(current_validation.replace(\"x.pickle\",\"y.pickle\"),'rb') as f:\n",
    "        validation_y = pickle.load(f) \n",
    "    if not first:\n",
    "        total_validation_x = np.concatenate((total_validation_x, validation_x))\n",
    "        total_validation_y = np.concatenate((total_validation_y, validation_y))\n",
    "    else:\n",
    "        total_validation_x = validation_x\n",
    "        total_validation_y = validation_y\n",
    "    first = False\n",
    "    \n",
    "for current_validation in test_batches_x:\n",
    "    print_log(\"Merging Test Batch:{}\".format(current_validation))\n",
    "    with gzip.open(current_validation,'rb') as f:\n",
    "        validation_x = pickle.load(f)\n",
    "    with gzip.open(current_validation.replace(\"x.pickle\",\"y.pickle\"),'rb') as f:\n",
    "        validation_y = pickle.load(f) \n",
    "    if not first:\n",
    "        total_validation_x = np.concatenate((total_validation_x, validation_x))\n",
    "        total_validation_y = np.concatenate((total_validation_y, validation_y))\n",
    "    else:\n",
    "        total_validation_x = validation_x\n",
    "        total_validation_y = validation_y\n",
    "    first = False    \n",
    "    \n",
    "validation_x = total_validation_x  \n",
    "validation_y = total_validation_y\n",
    "\n",
    "validation_x = validation_x.reshape(validation_x.shape[0], img_rows, img_cols,1)\n",
    "validation_y = validation_y.reshape(validation_y.shape[0])\n",
    "validation_y = keras.utils.to_categorical(validation_y, num_classes)  \n",
    "\n",
    "print_log(\"Finished merging validation batches...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_log(\"Number of Nuclei sample slices:{}\".format(len([x for x in validation_y if x[0] == 1])))\n",
    "print_log(\"Number of Non=Nuclei sample slices:{}\".format(len([x for x in validation_y if x[0] == 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.reshape(train_x.shape[0], img_rows, img_cols,1)\n",
    "test_x = test_x.reshape(test_x.shape[0], img_rows, img_cols,1)\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_batch = 0 \n",
    "\n",
    "for current_batch in range(global_epochs):\n",
    "    for current_train in train_batches_x:\n",
    "        i = datetime.now()\n",
    "        current_date_time = i.strftime('%Y%m%d.%H%M%S')\n",
    "        print(\"Training Batch:{}\".format(current_train))\n",
    "        batch_report = { 'batch_id' : current_batch , \n",
    "                         'batch_file' : current_train} \n",
    "\n",
    "        with gzip.open(current_train,'rb') as f:\n",
    "            train_x = pickle.load(f)\n",
    "        with gzip.open(current_train.replace(\"x.pickle\",\"y.pickle\"),'rb') as f:\n",
    "            train_y = pickle.load(f) \n",
    "\n",
    "        train_x = train_x.reshape(train_x.shape[0], img_rows, img_cols,1)\n",
    "        train_y = train_y.reshape(train_y.shape[0])\n",
    "        train_y = keras.utils.to_categorical(train_y, num_classes)\n",
    "        \n",
    "        if DevelopmentEnvironment:\n",
    "            train_x = train_x[:development_machine_samples]\n",
    "            train_y = train_y[:development_machine_samples]\n",
    "            validation_x = validation_x[:development_machine_samples]\n",
    "            validation_y = validation_y[:development_machine_samples]\n",
    "\n",
    "        model.fit(train_x, train_y,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  verbose=1, validation_data = (validation_x, validation_y))\n",
    "    \n",
    "        score = model.evaluate(validation_x, validation_y, verbose=1)\n",
    "        print_log('Test loss:'.format(score[0]))\n",
    "        print_log('Test accuracy:'.format(score[1]))\n",
    "        batch_report['score'] = (score)\n",
    "\n",
    "        model_file_name = join(PATH_TO_MODELS,'{}.model.meta.b{}.{}.h5'.format(current_date_time,current_batch,score[1]))\n",
    "        batch_report['model_file_name'] = model_file_name\n",
    "        with gzip.open(model_file_name,'wb') as f:\n",
    "            pickle.dump(batch_report, f, protocol=pickle.HIGHEST_PROTOCOL)  \n",
    "        model.save(model_file_name)\n",
    "        print_log('Model saved to:{}'.format(model_file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
